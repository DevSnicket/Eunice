shelving the multi-language analyzer written in Rust
Although I was making progress, I've decided to shelve the development of the multi-language analyzer I was writing in Rust. The decision wasn't based on the technology choices made (e.g. using Rust), but rather on how productive I believe creating a multi-language analyzer will be.
Libraries to analyze the syntax or semantics of a language are often only available to software written in that language, or those that share a runtime. So a new multi-language analyzer was being developed that would be limited to file/module/namespace imports. Basic parsing and regular expressions would be enough to implement this functionality.
As Rust was being used to implement the multi-language analyzer, the first language it would analyze was also Rust. However, I was finding that, even while limiting the analysis to file imports, which are syntactically unambiguous in Rust, it was taking a long time to implement.
After further research, I also realized that unlike Rust and other languages, comprehensive support for namespaces might be impractical. Based on my experience of C# code, support for packages in Java would miss dependencies, as this is possible without specifying an import.
While looking at Rust libraries that might be helpful and examples of what would be required to analyze other languages, it seemed for a lot of codebases, analysis of just file/namespace imports wouldn't be detailed enough. There was often structure only as multiple packages or services and then as code files, with little structure in between.
I think comprehensive support for fewer languages would be more useful. Doing so could include the ability to see inferred stacks for the contents of files. Supporting features like this would require syntax parsing or a semantic model, and thus require the creation of individual analyzers for each language.